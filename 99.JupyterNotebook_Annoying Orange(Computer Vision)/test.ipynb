{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 비디오나 화상캠을 사용해서 어노잉 오렌지 만들기!\n",
    "\n",
    "- 참고 사이트: 내 얼굴로 어노잉 오렌지 만들기: https://velog.io/@juijeong8324/%EC%BA%90%EA%B8%80%EC%8A%A4%ED%84%B0%EB%94%94-myface-orange\n",
    "\n",
    "- 만드려면 기본적으로 cv2, imutils, numpy 그리고 dlib이 필요함\n",
    "\n",
    "    - dlib library: 이미지 처리, 선형대수, 얼굴의 점 색출 및 머신러닝 알고리즘 사용 가능!\n",
    "\n",
    "    - 위의 라이브러리를 사용하려면 pip install cmake, pip install dlib를 해줘야 하며, visual studio c++이 있어야지 다운이 되는걸 확인함..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib \n",
    "import numpy as np\n",
    "from imutils import face_utils, resize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오렌지 사진 준비하기\n",
    "\n",
    "- imread를 통해 orange_img에 저장\n",
    "\n",
    "- cv2.resize()를 통해 이미지 사이즈 변경(512x512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orange_img = cv2.imread('orange.png') \n",
    "orange_img = cv2.resize(orange_img, dsize=(512,512)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dlib을 통해 얼굴 점 랜드마크 탐지\n",
    "\n",
    "- dlib 안에 있는 얼굴 영역 탐지 관련 메소드를 초기화 \n",
    "\n",
    "- 68개 점의 랜드 마크를 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector() \n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video.mp4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while cap.isOpened():\n",
    "    # read를 통해 img를 읽기\n",
    "    ret, img = cap.read() \n",
    "\n",
    "    # 보낼 프레임이 없다면 종료 \n",
    "    if not ret: \n",
    "        break\n",
    "\n",
    "    # 얼굴 영역을 인식,  이때 faces에 얼굴 영역 좌표가 담김    \n",
    "    faces = detector(img) \n",
    "\n",
    "    #Orange 이미지를 복사한 것 \n",
    "    result = orange_img.copy() \n",
    "\n",
    "    # 얼굴이 1개 이상이면, 즉 프레임도 한개 이상, 그중에서 첫번째 얼굴만 사용\n",
    "    if len(faces) > 0: \n",
    "        \n",
    "        # 그중에서 1개(첫 번째)의 얼굴만을 원한다.\n",
    "        face = faces[0]  \n",
    "\n",
    "        x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
    "        \n",
    "        # img에서 해당 face만 crop(잘라내기)해서 face_img에 저장\n",
    "        face_img = img[y1:y2, x1:x2].copy() \n",
    "\n",
    "        # 랜드마크의 68점을 찾는다\n",
    "        shape = predictor(img, face) \n",
    "        \n",
    "        # 원래 dlib 형태인 shape -> numpy 형태로 변환.\n",
    "        shape = face_utils.shape_to_np(shape)  \n",
    "\n",
    "        for p in shape:\n",
    "            cv2.circle(face_img, center=(p[0]-x1, p[1]-y1), radius=2, color=255, thickness=-1)\n",
    "\n",
    "        # ** 눈과 입을 잘라서 오렌지 파일에 붙이는 코드 **\n",
    "        # eyes\n",
    "        le_x1 = shape[36, 0] # **왼쪽 눈을 자르기 위해 x좌표 36번 39번, y좌표 37번 41번 인덱스가 필요**\n",
    "        le_y1 = shape[37, 1]\n",
    "        le_x2 = shape[39, 0]\n",
    "        le_y2 = shape[41, 1]\n",
    "        le_margin = int((le_x2 - le_x1) * 0.18) # 너무 가깝게 자르면 안 되니까 margin을 준다 \n",
    "\n",
    "        re_x1 = shape[42, 0] # 오른쪽 눈\n",
    "        re_y1 = shape[43, 1]\n",
    "        re_x2 = shape[45, 0]\n",
    "        re_y2 = shape[47, 1]\n",
    "        re_margin = int((re_x2 - re_x1) * 0.18)\n",
    "\n",
    "        # 여기서 왼쪽 눈과 오른쪽 눈에 margin을 준 값을 crop한다. \n",
    "        left_eye_img = img[le_y1-le_margin:le_y2+le_margin, le_x1-le_margin:le_x2+le_margin].copy() \n",
    "        right_eye_img = img[re_y1-re_margin:re_y2+re_margin, re_x1-re_margin:re_x2+re_margin].copy()\n",
    "\n",
    "        left_eye_img = resize(left_eye_img, width=100) # 가로를 100으로 resize\n",
    "        right_eye_img = resize(right_eye_img, width=100) \n",
    "\n",
    "        # ** opencv의 seamlessClone **\n",
    "        \n",
    "        # 왼쪽 눈 합성  \n",
    "        result = cv2.seamlessClone( \n",
    "            left_eye_img,\n",
    "            result, #result(오렌지 이미지를 복사한 것)에 합성 하는 것 \n",
    "            np.full(left_eye_img.shape[:2], 255, left_eye_img.dtype),\n",
    "            (100, 200),\n",
    "            cv2.MIXED_CLONE\n",
    "        )\n",
    "\n",
    "        # 오른쪽 눈 합성 \n",
    "        result = cv2.seamlessClone( \n",
    "            right_eye_img,\n",
    "            result,\n",
    "            np.full(right_eye_img.shape[:2], 255, right_eye_img.dtype),\n",
    "            (250, 200),\n",
    "            cv2.MIXED_CLONE\n",
    "        )\n",
    "\n",
    "        # mouth\n",
    "        mouth_x1 = shape[48, 0]\n",
    "        mouth_y1 = shape[50, 1]\n",
    "        mouth_x2 = shape[54, 0]\n",
    "        mouth_y2 = shape[57, 1]\n",
    "        mouth_margin = int((mouth_x2 - mouth_x1) * 0.1)\n",
    "\n",
    "        mouth_img = img[mouth_y1-mouth_margin:mouth_y2+mouth_margin, mouth_x1-mouth_margin:mouth_x2+mouth_margin].copy()\n",
    "\n",
    "        mouth_img = resize(mouth_img, width=250)\n",
    "        \n",
    "        # 입 합성 \n",
    "        result = cv2.seamlessClone( \n",
    "            mouth_img,\n",
    "            result,\n",
    "            np.full(mouth_img.shape[:2], 255, mouth_img.dtype),\n",
    "            (180, 320),\n",
    "            cv2.MIXED_CLONE\n",
    "        )\n",
    "\n",
    "        # cv2.imshow('left', left_eye_img)\n",
    "        # cv2.imshow('right', right_eye_img)\n",
    "        # cv2.imshow('mouth', mouth_img)\n",
    "        # cv2.imshow('face', face_img)\n",
    "\n",
    "        cv2.imshow('result', result)\n",
    "        \n",
    "    # cv2.imshow('img', img)\n",
    "    if cv2.waitKey(0) == ord('q'):\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e89c93e4c07d4ac8f065cea982a638287e1c61026788fcbbad7e0263e2130583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
